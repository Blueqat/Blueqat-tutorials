{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coated-southeast",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "Matrix Factorization はリコメンドエンジンに用いられる機械学習アルゴリズムです。\n",
    "\n",
    "身近なリコメンドエンジンの例は、通販サイトの\"おすすめ商品\"欄です。ユーザーAの過去の購入履歴から、似たような購買傾向を持つ他のユーザーBを割り出すことができます。ユーザーBが過去に購入した商品はユーザーAも欲しがる可能性が高いため、おすすめ商品として表示することで購入を促す仕組みです。\n",
    "\n",
    "今回は量子アニーリングを用いて Matrix Factorization を実行します。  \n",
    "\n",
    "参考文献: O’Malley, Daniel, et al. \"Nonnegative/binary matrix factorization with a d-wave quantum annealer.\" PloS one 13.12 (2018): e0206653."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-arabic",
   "metadata": {},
   "source": [
    "データセットとして MovieLens dataset (https://grouplens.org/datasets/movielens/100k/) を用います。  \n",
    "1682種類の映画に対する943ユーザーによる100,000回分の評価(星1~星5)のデータセットです。\n",
    "\n",
    "まずデータセットを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unable-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90570, 4), (9430, 4))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataDir = './Data/'\n",
    "\n",
    "#Reading users file:\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv(dataDir + 'ml-100k/u.user', sep='|', names=u_cols,encoding='latin-1')\n",
    "\n",
    "#Reading ratings file:\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(dataDir + 'ml-100k/u.data', sep='\\t', names=r_cols,encoding='latin-1')\n",
    "\n",
    "#Reading items file:\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    "'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "items = pd.read_csv(dataDir + 'ml-100k/u.item', sep='|', names=i_cols,\n",
    "encoding='latin-1')\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_train = pd.read_csv(dataDir + 'ml-100k/ua.base', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv(dataDir + 'ml-100k/ua.test', sep='\\t', names=r_cols, encoding='latin-1')\n",
    "ratings_train.shape, ratings_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-deposit",
   "metadata": {},
   "source": [
    "データセットは訓練用とテスト用に分かれています。  \n",
    "中身は以下の通りです。\"user_id\" の示すユーザーが \"movie_id\" の示す映画に与えた評価が \"rating\" として記録されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bright-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90565</th>\n",
       "      <td>943</td>\n",
       "      <td>1047</td>\n",
       "      <td>2</td>\n",
       "      <td>875502146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90566</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90567</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90568</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90569</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  unix_timestamp\n",
       "0            1         1       5       874965758\n",
       "1            1         2       3       876893171\n",
       "2            1         3       4       878542960\n",
       "3            1         4       3       876893119\n",
       "4            1         5       3       889751712\n",
       "...        ...       ...     ...             ...\n",
       "90565      943      1047       2       875502146\n",
       "90566      943      1074       4       888640250\n",
       "90567      943      1188       3       888640250\n",
       "90568      943      1228       3       888640275\n",
       "90569      943      1330       3       888692465\n",
       "\n",
       "[90570 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-illustration",
   "metadata": {},
   "source": [
    "これを行列に成型します。\n",
    "行が \"user_id\"、列が \"movei_id\"、各要素がその行と列に対応する \"rating\" となります。\n",
    "\n",
    "ここでは問題サイズの観点から \"user_id\"、\"movei_id\" ともに100までのデータのみを抽出し、100 x 100 行列とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "theoretical-serum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "user_num = 100 # Max.943\n",
    "item_num = 100 # Max.1680\n",
    "\n",
    "def df_to_matrix(df, user_num, item_num, row_name, col_name, values):\n",
    "    df1 = df[df[row_name] <= user_num]\n",
    "    df2 = df1[df1[col_name] <= item_num]\n",
    "    for i in range(1, user_num+1):\n",
    "        if len(df2.loc[(df2.loc[:,row_name]==i)]) == 0:\n",
    "            df2 = df2.append(pd.DataFrame([[i,1]], columns=[row_name, col_name])).fillna(0)\n",
    "    for i in range(1, item_num+1):\n",
    "        if len(df2.loc[(df2.loc[:,col_name]==i)]) == 0:\n",
    "            df2 = df2.append(pd.DataFrame([[1,i]], columns=[row_name, col_name])).fillna(0)\n",
    "    \n",
    "    return np.array(df2.pivot(index = row_name, columns =col_name, values = values).fillna(0))\n",
    "   \n",
    "R = df_to_matrix(ratings_train, user_num, item_num, 'user_id', 'movie_id', 'rating')\n",
    "print(R.shape)\n",
    "\n",
    "R_test = df_to_matrix(ratings_test, user_num, item_num, 'user_id', 'movie_id', 'rating')\n",
    "print(R_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "green-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 4., 3., 5.],\n",
       "       [4., 0., 0., ..., 0., 0., 5.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 3., ..., 5., 0., 5.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-prison",
   "metadata": {},
   "source": [
    "このような行列を Matrixf Factorization では下図のように分解します。\n",
    "\n",
    "$$\n",
    "V \\approx WH \\\\\n",
    "$$\n",
    "\n",
    "<img src=\"./img/212_img.png\" width=\"50%\">\n",
    "\n",
    "\"features\" はユーザーと映画がそれぞれ持つ特徴量を表しています。  \n",
    "特徴量とは例えばユーザーについて\"アクション映画が好き\"というような好みや傾向を表します。  映画の特徴量も同様に\"アクション映画か否か\"といった傾向を表すことができます。  \n",
    "このように定式化すると、アクション映画が好きなユーザーはまだ見ぬアクション映画に対しても高い評価をつけると予想します。  \n",
    "\n",
    "Matrix Factorization では $V \\approx WH $ をなるべく精度良く満たせるような $W, H$ を求めます。  \n",
    "特に $W$ を正の値とし、$H$ をバイナリ(0 または 1)値に限定した問題は Nonnegative/Binary Matrix Factorization (NBMF) と呼ばれます。  \n",
    "\n",
    "NBMF は以下の最適化を繰り返し $W, H$ を更新していきます。\n",
    "\n",
    "$$\n",
    "W = \\mathrm{argmin}_{X \\in \\mathbb{R}+^{M\\times K}} \\| V - XH \\|_F  + \\alpha \\| X \\|_F\n",
    "$$\n",
    "\n",
    "$$\n",
    "H = \\mathrm{argmin}_{X \\in \\{0,1\\}^{K\\times N} } \\|V - WX \\|_F\n",
    "$$\n",
    "\n",
    "さらに、$H$ の各列 $i$ ($H_i$) は次式のように独立に最適化できます。\n",
    "\n",
    "$$\n",
    "H_i = \\mathrm{argmin}_{q \\in \\{0,1\\}^k } \\|V_i-Wq \\|_F\n",
    "$$\n",
    "\n",
    "$\\| \\cdot \\|_F$ はフロベニウスノルムを表します。  \n",
    "$H$ はバイナリとしていたため、$q$ を求めるために量子アニーリングを活用できます。  \n",
    "具体的には線形最小二乗問題に帰着でき、以下のようなQUBO定式化が知られています。  \n",
    "\n",
    "$$\n",
    "f(q) = \\sum_i a_i q_i + \\sum_{i<j} b_{ij}q_i q_j  \\\\\n",
    "a_j = \\sum_k W_{kj}(W_{kj} - 2V_{ki}) \\\\\n",
    "b_{jk} = 2\\sum_l W_{lj}W_{lk}\n",
    "$$\n",
    "\n",
    "参考: Borle, Ajinkya, and Samuel J. Lomonaco. \"Analyzing the quantum annealing approach for solving linear least squares problems.\" International Workshop on Algorithms and Computation. Springer, Cham, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-telephone",
   "metadata": {},
   "source": [
    "### 実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-junction",
   "metadata": {},
   "source": [
    "blueqat で実装してみましょう。  \n",
    "以下は量子アニーリングとQAOAの両方で実行できるようにしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pointed-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import blueqat.wq as wq\n",
    "from blueqat import vqe\n",
    "from blueqat.pauli import qubo_bit as q\n",
    "\n",
    "class MF():\n",
    "\n",
    "    def __init__(self, V, K, alpha, iterations, Aneal_iteration, method):\n",
    "        self.V = V\n",
    "        self.num_users, self.num_items = V.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.iteAneal = Aneal_iteration\n",
    "        self.step = 5 # QAOA step\n",
    "        self.method = method\n",
    "\n",
    "    def train(self):\n",
    "        # Initializing user-feature and movie-feature matrix \n",
    "        self.b = np.mean(self.V[np.where(self.V != 0)]) # bias term\n",
    "        self.W = np.abs((np.random.normal(scale=self.b/self.K, size=(self.num_users, self.K))))\n",
    "        self.H = np.abs((np.random.normal(scale=1./2, size=(self.K, self.num_items))))\n",
    "\n",
    "        self.predictedIndex = []\n",
    "        self.itemVecs = []\n",
    "        self.itemVecs_indices = []\n",
    "        for j in range(self.num_items):\n",
    "            self.itemVecs.append([])\n",
    "            self.itemVecs_indices.append([])\n",
    "            for i in range(self.num_users):\n",
    "                if self.V[i, j] > 0:\n",
    "                    self.itemVecs[j].append(self.V[i, j]) # jth column's non 0 elements \n",
    "                    self.itemVecs_indices[j].append(i) # jth column's non 0 indices\n",
    "        \n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            #np.random.shuffle(self.samples)\n",
    "            self.train_W()\n",
    "            if self.method == 'QAOA':\n",
    "                self.train_H_QAOA()\n",
    "            elif self.method == 'Anneal':\n",
    "                self.train_H_Anneal()\n",
    "            aveError = self.aveError()\n",
    "            if (i+1) % 1 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, aveError))\n",
    "            if i>0 and np.abs(aveError - training_process[-1][1]) < aveError/50: # convergence\n",
    "                break\n",
    "            else:\n",
    "                training_process.append((i, aveError))\n",
    "        return training_process\n",
    "\n",
    "    # Computing mean error\n",
    "    def aveError(self):\n",
    "        xs, ys = self.V.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        l = len(xs)\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += np.abs(self.V[x, y] - predicted[x, y])\n",
    "        return error / l\n",
    "\n",
    "    # Stochastic gradient descent to get optimized W matrix\n",
    "    def train_W(self):\n",
    "        self.Wdiff = np.zeros([self.num_users, self.K])\n",
    "        for i in range(self.num_users):\n",
    "            for q in range(self.K):\n",
    "                for j in range(self.num_items):\n",
    "                    if self.V[i][j] == 0:\n",
    "                        continue\n",
    "                    self.Wdiff[i][q] += 2 * (self.V[i][j] - np.dot(self.W[i,:], self.H[:,j])) * (-1 * self.H[q][j])\n",
    "        self.W = np.abs(self.W - self.alpha * self.Wdiff)\n",
    "\n",
    "    def train_H_QAOA(self):\n",
    "        # use QAOA method\n",
    "        for j in range(self.num_items): #jth column of V    \n",
    "            # define QUBO hamiltonian and solve\n",
    "            self.hamiltonian = 0\n",
    "            for l in range(self.K):\n",
    "                for m in range(l,self.K):\n",
    "                    if l==m: # diagonal elements\n",
    "                        for k in self.itemVecs_indices[j]: #jth columns's k's element\n",
    "                            self.hamiltonian += np.float(self.W[k][l] * (self.W[k][l] - 2 * self.V[k][j])) * q(l)\n",
    "                    else:\n",
    "                        for k in self.itemVecs_indices[j]:\n",
    "                            self.hamiltonian += 2 * np.float(self.W[k][l] * self.W[k][m]) * q(l) * q(m)\n",
    "            result = vqe.Vqe(vqe.QaoaAnsatz(self.hamiltonian, self.step)).run()\n",
    "            self.H[:,j] = list(result.most_common(1)[0][0])\n",
    "            \n",
    "    def train_H_Anneal(self):\n",
    "        # use Q-Anealing\n",
    "        self.JthAneal = 0\n",
    "        for j in range(self.num_items): #jth column of V\n",
    "            for ite in range(self.iteAneal): # iteration of anealing\n",
    "                # define QUBO and solve\n",
    "                self.a = wq.Opt()\n",
    "                self.a.qubo = l_2d_ok = [[0] * self.K for i in range(self.K)] # initialize qubo matrix\n",
    "                for l in range(self.K):\n",
    "                    for m in range(l,self.K):\n",
    "                        if l==m: # diagonal elements\n",
    "                            for k in self.itemVecs_indices[j]: #jth columns's k's element\n",
    "                                self.a.qubo[l][m] += self.W[k][l] * (self.W[k][l] - 2 * self.V[k][j])\n",
    "                        else:\n",
    "                            for k in self.itemVecs_indices[j]:\n",
    "                                self.a.qubo[l][m] += 2 * self.W[k][l] * self.W[k][m]\n",
    "                \n",
    "                tmp = self.a.sa()\n",
    "                tmp_error = self.error_aneal(tmp)\n",
    "                if ite == 0:\n",
    "                    self.anealBit = tmp\n",
    "                    min_error = self.error_aneal(tmp)\n",
    "                else: # update or not\n",
    "                    if tmp_error < min_error:\n",
    "                        self.anealBit = tmp\n",
    "            \n",
    "            self.H[:,j] = self.anealBit\n",
    "                \n",
    "    def error_aneal(self, anealBit):\n",
    "        F = 0\n",
    "        for l in range(self.K):\n",
    "            for m in range(l,self.K):\n",
    "                if l==m: # diagonal elements\n",
    "                    F += self.a.qubo[l][m] * anealBit[l]\n",
    "                else:\n",
    "                    F += self.a.qubo[l][m] * anealBit[l] * anealBit[m]\n",
    "        return abs(F)        \n",
    "\n",
    "    # Full user-movie rating matrix\n",
    "    def full_matrix(self):\n",
    "        return self.W.dot(self.H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-brown",
   "metadata": {},
   "source": [
    "### 学習\n",
    "\n",
    "学習を行います。  \n",
    "エラーの減少が一定程度収束したら学習を終了します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "registered-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 ; error = 1.1610\n",
      "Iteration: 2 ; error = 0.8512\n",
      "Iteration: 3 ; error = 0.8231\n",
      "Iteration: 4 ; error = 0.7669\n",
      "Iteration: 5 ; error = 0.8519\n",
      "Iteration: 6 ; error = 0.7382\n",
      "Iteration: 7 ; error = 0.7189\n",
      "Iteration: 8 ; error = 0.7329\n",
      "\n",
      "W x H:\n",
      "[[3.07752757 1.57568632 2.76098952 ... 3.07752757 2.21578174 3.29777999]\n",
      " [3.12600217 3.17252369 2.18554561 ... 3.12600217 2.10711165 3.93359492]\n",
      " [1.68016056 2.22742145 0.92386796 ... 1.68016056 2.23645789 2.994783  ]\n",
      " ...\n",
      " [3.03236212 3.19494034 1.54332623 ... 3.03236212 3.34842419 3.8458737 ]\n",
      " [4.35070465 3.87558426 2.96300904 ... 4.35070465 3.45499378 5.10746399]\n",
      " [1.17751116 1.72820597 0.50113742 ... 1.17751116 1.69326523 2.03189509]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed = 42\n",
    "mf = MF(R, K=5, alpha=0.01, iterations=20, Aneal_iteration=1, method='Anneal')\n",
    "training_process = mf.train()\n",
    "print()\n",
    "print(\"W x H:\")\n",
    "print(mf.full_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-increase",
   "metadata": {},
   "source": [
    "### 予測性能の確認\n",
    "\n",
    "学習したユーザーと映画の特徴量を用いて、ユーザーのまだ見ていない映画に対する評価を予測しましょう。  \n",
    "予測するユーザーと映画の組み合わせはテストデータに含まれているものとし、テストデータにおける評価を正解とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "compressed-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = mf.full_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stable-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedRating = []\n",
    "testRating = []\n",
    "score = [[],[],[],[],[]]\n",
    "\n",
    "xs, ys = R_test.nonzero()\n",
    "\n",
    "error_test = 0\n",
    "for x,y in zip(xs, ys):\n",
    "    predictedRating.append(prediction[x][y])\n",
    "    testRating.append(R_test[x][y])\n",
    "    score[int(R_test[x][y] - 1)].append(min(prediction[x][y],5))\n",
    "\n",
    "    error_test += np.abs(R_test[x][y] - prediction[x][y])\n",
    "error_test = error_test / len(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-teach",
   "metadata": {},
   "source": [
    "テストデータで評価が 1, 2, 3, 4, 5点だったデータの平均予測点をそれぞれ算出してみましょう。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "unavailable-principal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error = 0.8367807157320516\n",
      "\n",
      "Test dataでそれぞれ1,2,3,4,5点だった箇所の予測点数平均\n",
      "2.473954521232848 \n",
      " 3.3221181082768103 \n",
      " 3.5287032057191428 \n",
      " 3.6094973953846186 \n",
      " 4.093452207661236\n"
     ]
    }
   ],
   "source": [
    "print('Test error =', error_test)\n",
    "print()\n",
    "print('Test dataでそれぞれ1,2,3,4,5点だった箇所の予測点数平均')\n",
    "print(np.mean(score[0]), '\\n',\n",
    "     np.mean(score[1]), '\\n',\n",
    "     np.mean(score[2]), '\\n',\n",
    "     np.mean(score[3]), '\\n',\n",
    "     np.mean(score[4]),)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-committee",
   "metadata": {},
   "source": [
    "全体としては、テストデータと予測結果で高評価/低評価の傾向は合っていることがわかります。  \n",
    "今回の条件における学習では 2, 3, 4点の判別は難しそうですが、１点と5点はそれなりに判別できそうです。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-connectivity",
   "metadata": {},
   "source": [
    "以上より、量子アニーリング/QAOAを用いて Matrix Factorization を用いた推薦アルゴリズムを実装しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-replacement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
